{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Import and Review Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "* 'Fetch data from Kaggle and save as raw data'\n",
        "\n",
        "### Inputs\n",
        "\n",
        "* [Ocean Trash Locator]()\n",
        "* [House Price Predictor]()\n",
        "* [Skin Checker]()\n",
        "* [Disease Screener]()\n",
        "* [Oil Slick Spread Predictor]()\n",
        "* [Dog Emotions]()\n",
        "* [Filter Maintenance](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance)\n",
        "\n",
        "### Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "### Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chdir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print('You set a new current directory')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After importing your **kaggle.json** token file; run the following to recognize it in the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are using the following Kaggle URL: [https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- ![image.png](https://static.streamlit.io/examples/cat.jpg) -->\n",
        "![image.png](/workspace/dataset-testing/static/img/PPM_Dataset_Kaggle.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the dataset path from the Kaggle url\n",
        "* When you are viewing the dataset at Kaggle, check what is after '[https://www.kaggle.com/datasets/](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance)' .\n",
        "\n",
        "The following function: \n",
        "* Retrieves the Kaggle dataset\n",
        "* Creates a destination folder folder for the data to be placed\n",
        "* Downloads it to the destination folder\n",
        "* Unzips the downloaded file\n",
        "* Deletes the **.zip** file \n",
        "* Deletes unused copies of the data as MATLAB **.mat** files\n",
        "* Removes any  **kaggle.json** files used to access the dataset on Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = 'prognosticshse/preventive-to-predicitve-maintenance'\n",
        "DestinationFolder = 'inputs/datasets/raw'   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}\n",
        "\n",
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm {DestinationFolder}/*.pdf \\\n",
        "  && rm {DestinationFolder}/*.mat \\\n",
        "#   && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load and Inspect Kaggle data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Data to Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv(f'inputs/datasets/raw/Test_Data_CSV.csv')\n",
        "df_train = pd.read_csv(f'inputs/datasets/raw/Train_Data_CSV.csv')\n",
        "# df_play = pd.read_csv(f'inputs/datasets/raw/Train_Data_CSV.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Composition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ideally, the split of these subsets from a single dataset would be:\n",
        "* Training Set = 70-80% (to fit the model)\n",
        "* Test Set = 20-30%\n",
        "* Validation Set = 10-20% (cross validation, compare models and choose hyperparameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.to_numpy()\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.to_numpy()\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['Data_No'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_size = float(df_train['Data_No'].count())\n",
        "test_size = float(df_test['Data_No'].count())\n",
        "print(f'Train Data Shape {df_train.shape}; is {(train_size / (train_size + test_size))*100:.2f}% of the total data')\n",
        "print(f'Test Data Shape {df_test.shape}; is {(test_size / (train_size + test_size))*100:.2f}% of the total data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.Data_No.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_index = df_test['Data_No'].unique()\n",
        "# df_train['Data_No'].nunique()\n",
        "data_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_index[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting the data\n",
        "Easier to do add calculations df_test and df_train datasets first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "random_list = list(df_test['Data_No'].unique())\n",
        "random_test = random.sample(random_list, 20)\n",
        "random_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_by_sets = df_test.groupby(['Data_No'])\n",
        "grouped_by_sets.get_group(23)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row1 = df_test.loc[[4, 5, 6, 7]]\n",
        "row1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/workspace/dataset-testing/inputs/datasets/raw/Test_Data_CSV.csv\", index_col =\"Data_No\")\n",
        "df_test_rows = data.loc[15:20]\n",
        "df_test_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "data = pd.read_csv(\"/workspace/dataset-testing/inputs/datasets/raw/Test_Data_CSV.csv\", index_col=\"Data_No\")\n",
        "# df_test_copy = pd.read_csv(\"/workspace/dataset-testing/inputs/datasets/raw/Train_Data_CSV.csv\", index_col =\"Data_No\")\n",
        "random_list = list(df_test['Data_No'].unique())\n",
        "select_random = random.sample(random_list, 20)\n",
        "df_validate = data.loc[select_random]\n",
        "df_validate.shape\n",
        "df_validate.sort_values('Data_No', ascending=True)\n",
        "print(select_random)\n",
        "print('------')\n",
        "print('Randomized data to be extracted to db_validate:')\n",
        "df_validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "select_random.sort()\n",
        "print('Data to be extracted to db_validate (in order):')\n",
        "select_random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shape of data BEFORE splitting Validation data from df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "df_test data with df_validation data removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test_copy = df_test\n",
        "df_test_less_validations = df_test_copy[~df_test_copy['Data_No'].isin(select_random)]\n",
        "# print (df_test_less_validations)\n",
        "df_test_less_validations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New training data shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test_less_validations.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace the indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_validate.reset_index(inplace=True, drop=False)\n",
        "df_test_less_validations.reset_index(inplace=True, drop=True)\n",
        "df_validate.shape\n",
        "df_validate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test_less_validations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List the shapes of the remaining data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = [df_train, df_test_less_validations, df_validate]\n",
        "\n",
        "for df in dfs:\n",
        "    print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Update Working Variables "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New df_test File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = df_test_less_validations\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add Mass Calculations\n",
        "\n",
        "* add single data: \n",
        "`dataframe[new_column] = 'Value'`\n",
        "\n",
        "* add multiple data: `dataframe[new_column0, new_column1, new_column2] = [val1, val2, val3]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Include numerical values fot Dust Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['Dust_Density'] = [0.900 if n == 'ISO 12103-1, A2 Fine Test Dust' else (1.025 if n == 'ISO 12103-1, A3 Medium Test Dust' else 1.200) for n in df_test['Dust']]\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def dust_in_grams_cm3(n):\n",
        "#     if n == 'ISO 12103-1, A2 Fine Test Dust':\n",
        "#        return 0.900\n",
        "#     elif n == 'ISO 12103-1, A3 Medium Test Dust':\n",
        "#        return 1.025\n",
        "#     else:\n",
        "#        return 1.200\n",
        "\n",
        "# df_test['Dust_Density'] = df_test['Dust'].apply(dust_in_grams_cm3)\n",
        "# df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mass per observation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Mass_g'] = (df_test.Dust_feed/1000)*df_test.Dust_Density\n",
        "df_test.loc[:,('Mass_g')] = (df_test.Dust_feed/1000)*df_test.Dust_Density\n",
        "df_test.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cumulative Mass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test.Data_No\n",
        "df_test['Cumulative_Mass_g'] = df_test['Mass_g'].groupby(data).cumsum()\n",
        "df_test.head()\n",
        "df_test.loc[600:610]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cumulative Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Ts'] = df_test['Time'].diff().fillna(df_test[df_test.Data_No != df_test.Data_No.shift(1)].Time)\n",
        "# df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Ts'] = df_test['Time'].diff().fillna(df_test[df_test.Data_No != df_test.Data_No.shift(1)].Time)\n",
        "# df_test.loc[1211:1220]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For Review\n",
        "#### Correct for time Change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test = df_test.Data_No / df_test.Data_No.shift(1)\n",
        "# # test.loc[1211:1220].squeeze()\n",
        "# test.loc[1211:1220]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t_list = test.to_frame()\n",
        "# t_list[1211:1220]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # test = (df_test.Data_No / df_test.Data_No.shift(1)).to_list()\n",
        "# t_list = test.to_list()\n",
        "# time_diff = df_test['Time'].diff().fillna(df_test[df_test.Data_No != df_test.Data_No.shift(1)].Time)\n",
        "# # time_rel = df_test[df_test.Data_No != df_test.Data_No.shift(1)]\n",
        "# time_rel = df_test.Data_No.shift(1) - time_diff\n",
        "\n",
        "# for i in test:\n",
        "#     if i == 1:\n",
        "#         # print('True')\n",
        "#         df_test['Ts'] = time_diff\n",
        "#     else:\n",
        "#         # print('False')\n",
        "#         df_test['Ts'] = time_rel\n",
        "# # df_test.head()\n",
        "# df_test.loc[1211:1222]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first_row_time = df_test[df_test.Data_No != df_test.Data_No.shift(1)]\n",
        "# first_row_time.Time.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test = df_test.Data_No / df_test.Data_No.shift(1)\n",
        "# first_row_time = df_test[df_test.Data_No != df_test.Data_No.shift(1)].Time\n",
        "# # first_row_time\n",
        "# for df_test['Ts'] in df_test:\n",
        "#     if test.tolist() == 1:\n",
        "#         df_test['Ts'] = df_test[df_test.Data_No != df_test.Data_No.shift(1)].Time\n",
        "#     else:\n",
        "#         df_test['Ts'] = df_test['Time'].diff().fillna(df_test[df_test.Data_No != df_test.Data_No.shift(1)].Time)\n",
        "#         # pass\n",
        "    \n",
        "# df_test.loc[365:370]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Total Time Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "time_total = df_test['Time'].groupby(data).max().to_frame()\n",
        "time_total.index.name = None\n",
        "time_total['Data_No'] = time_total.index\n",
        "# time_total.reset_index(level=None, inplace=False).head()\n",
        "# time_total_series = time_total.squeeze()\n",
        "# time_total.to_frame()\n",
        "# time_total_series\n",
        "time_total.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total.index.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# time_total.Time[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total.index[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total.index[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(int(time_total.index[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(time_total.Data_No)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(time_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# time_total = time_total.drop(axis=1, columns='index_no')\n",
        "# time_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To convert it into a series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total.squeeze().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### .Map() Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total.Time.map('I am a {}'.format).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert Total Time Tt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['Total_Test_T'] = df_test['Data_No'].map(time_total.set_index('Data_No')['Time'])\n",
        "df_test.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test.Data_No\n",
        "df_test['Time'].groupby(data).max()[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.loc[365:370]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert time Interval Ts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Time Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # import pandas as pd\n",
        "# data = df_test.Data_No\n",
        "# time_start = df_test['Time'].groupby(data).min().to_frame()\n",
        "# time_start.index.name = None\n",
        "# time_start['Data_No'] = time_start.index\n",
        "# time_start.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Ts'] = df_test['Data_No'].map(time_start.set_index('Data_No')['Time'])\n",
        "# df_test.loc[365:370]\n",
        "# df_test.loc[1211:1220]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Data_No']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# time_total.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# time_total.index.to_series()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RUL\n",
        "\n",
        "Remaining Useful Life (RUL) = Total time (cycles) to failure for each life test (T) - current time (t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.loc[1210:1220]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test.Data_No\n",
        "RUL_end = df_test['RUL'].groupby(data).min().to_frame()\n",
        "RUL_end.index.name = None\n",
        "RUL_end['Data_No'] = RUL_end.index\n",
        "RUL_end.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUL_Start = df_test['Data_No'].map(RUL_end.set_index('Data_No')['RUL'])\n",
        "# RUL_Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data = df_test.Data_No\n",
        "# RUL = (df_test['Total_Test_T'] - df_test['Time']) + RUL_Start\n",
        "# RUL.loc[1210:1220]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data = df_test.Data_No\n",
        "# RUL = (df_test['Total_Test_T'] - df_test['Time']) + RUL_Start\n",
        "# RUL.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RUL for df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test.Data_No\n",
        "RUL_Start = df_test['Data_No'].map(RUL_end.set_index('Data_No')['RUL'])\n",
        "df_test['RUL_test'] = (df_test['Total_Test_T'] - df_test['Time']) + RUL_Start\n",
        "df_test.loc[1210:1220]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RUL for df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data = df_train.Data_No\n",
        "# RUL_Start = df_train['Data_No'].map(RUL_end.set_index('Data_No')['RUL'])\n",
        "# df_train['RUL_test'] = (df_train['Total_Test_T'] - df_train['Time']) + RUL_Start\n",
        "# df_train.loc[1210:1220]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Investigate Data Splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create print variable name function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_variable_name(data):\n",
        "    name =[x for x in globals() if globals()[x] is data][0]\n",
        "    print(\"%s\"%name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = [df_train, df_test, df_validate]\n",
        "\n",
        "train = int(df_train.Data_No.count())\n",
        "test = int(df_test.Data_No.count())\n",
        "validation = int(df_validate.Data_No.count())\n",
        "total = test + train + validation\n",
        "\n",
        "for df in dfs:\n",
        "    # print(f'{print_variable_name(df)}{df.shape} = {(int(df.Data_No.count())/total)*100:.2f}% split')\n",
        "    print(f'{df.shape} = {(int(df.Data_No.count())/total)*100:.2f}% split')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.shape\n",
        "# df_test.shape\n",
        "# df_validate.shape\n",
        "# df_test_less_validations.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Copy of the Datasets for Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "# df.to_csv(f'outputs/datasets/collection/FilterMaintenancePredictorDataset.csv',index=False)\n",
        "df_train.to_csv(f'outputs/datasets/collection/df_train.csv',index=False)\n",
        "df_test.to_csv(f'outputs/datasets/collection/df_test.csv',index=False)\n",
        "df_validate.to_csv(f'outputs/datasets/collection/df_validate.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scrapbook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test_np = df_test.to_numpy()\n",
        "# df_test_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Data_No'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_test_row = []\n",
        "for col in df_test.columns.values:\n",
        "    last_test_row.append(df_test[col].iloc[-1])\n",
        "print(last_test_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List of the observations at the end of each life test. \n",
        "Used to answer the question:\n",
        "* **Did the filter fail at the end of the test**?\n",
        "    * Will help us indicate if the test is part of the right censored test group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Last Values in each Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# last_test_row = df_test[df_test.Data_No != df_test.Data_No.shift(-1)]['Time']\n",
        "last_test_row = df_test[df_test.Data_No != df_test.Data_No.shift(-1)]\n",
        "last_test_row.head()\n",
        "# (last_test_row*10).head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Total_Test_T'] = last_test_row.Time\n",
        "# df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# last_test_row.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_test_row.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_test_row.iloc[0]['Time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_test_row.iloc[0]['Data_No']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_test_row.index + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To detect a change in the observation value at 'Data_No'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr2 = [2, 2, 2, 3, 3, 1, 2, 2, 9, 4, 4]\n",
        "# index = arr2.index(item)\n",
        "\n",
        "for n in range(len(arr2)):\n",
        "    if arr2[n] == arr2[n-1]:\n",
        "        print(f'Same values!')\n",
        "    else:\n",
        "        print(f'Value Change: Current = {arr2[n]} to Previous = {arr2[n-1]}!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['Data_No'].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test['Data_No']\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.Data_No[4454]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_index[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_test_row.iloc[0]['Time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test['Data_No']\n",
        "# index_ref = last_test_row.iloc[data.index]['Time']\n",
        "\n",
        "for n in range(len(data)-1):\n",
        "    if data[n] != data[n+1]:\n",
        "        print(f'Value Change at index : {data.index[n+2]}')\n",
        "        # data['Total_Test_T'] = last_test_row.iloc[df_test.Data_No[n-1]]['Time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data = df_test['Data_No']\n",
        "# # index_ref = last_test_row.iloc[data.index]['Time']\n",
        "\n",
        "# for n in range(len(data)+1):\n",
        "#     if data[n+1] != data[n]:\n",
        "#         # print(f'Value Change: Current = {data[n]} to Next = {data[n+1]}! Current Index: {data.index[n]}')\n",
        "#         # print(f'Value Change at index : {data.index[n+2]} to last_test_row.iloc[\"data\"-1][\"Time\"]')\n",
        "#         data[n+1] = last_test_row.iloc[df_test.Data_No[n]]['Time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for n in df_test['Data_No']:\n",
        "#     if df_test.Data_No[n] > df_test.Data_No[n-1]:\n",
        "#         df_test['Total_Test_T'] = last_test_row.Time\n",
        "# df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_train['Data_No'].value_counts().unique()\n",
        "# df_train['Data_No'].value_counts()\n",
        "count = df_train.groupby(['Data_No']).count()\n",
        "# print(count.head())\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.columns[6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Data\n",
        "* includes the Remaining Useful Life (RUL) target variable sourced from live measures "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test DataFrame Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.info()\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List of the observations at the end of each life test. \n",
        "Used to answer the question:\n",
        "* **Did the filter fail at the end of the test**?\n",
        "    * Will help us indicate if the test is part of the right censored test group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test('2').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(-1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train DataFrame Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.info()\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train[df_train.Data_No != df_train.Data_No.shift(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train[df_train.Data_No != df_train.Data_No.shift(-1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push Files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add RUL column to Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_train.insert(loc=6, column='RUL', value=0.0, allow_duplicates=False)\n",
        "# df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_train.dtypes['RUL']\n",
        "# df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Combine Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_list = [df_test, df_train, df_validate]\n",
        "df = pd.concat(combined_list)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with 'Conclusions and Next Steps' and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# try:\n",
        "#   os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "# except Exception as e:\n",
        "#   print(e)\n",
        "\n",
        "# df.to_csv(f'outputs/datasets/collection/df_total.csv',index=False)\n",
        "# df_test.to_csv(f'outputs/datasets/collection/df_test.csv',index=False)\n",
        "# df_train.to_csv(f'outputs/datasets/collection/df_train.csv',index=False)\n",
        "# df_validate.to_csv(f'outputs/datasets/collection/df_validate.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notes Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Combine Train & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df_test = pd.read_csv(f'inputs/datasets/raw/Test_Data_CSV.csv')\n",
        "# df_train = pd.read_csv(f'inputs/datasets/raw/Train_Data_CSV.csv')\n",
        "# combined_list = [df_test, df_train]\n",
        "# df = pd.concat(combined_list)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.duplicated(subset=['Data_No'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Impute Missing Remaining Useful Life (RUL) Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The RUL information of the test data is not an estimate, rather the actual time when the experiment exceeded the threshold. \n",
        "    * In order to define a specific test problem, the measurements in the test data set are right-censored at random points and only the corresponding RUL information is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Underfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check missing data:\n",
        "* https://docs.google.com/document/d/1yXb5g5IU7IldBpND1FbIfHIyGGmNSlXogarAyBlNO_g/edit?usp=sharing\n",
        "* df.isnull()\n",
        "* df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull()\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can calculate the value to be filled in. \n",
        "* The example below calculates the mean for column A and inserts this value where it is missing for that column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df['RUL'].fillna(value=df['RUL'].mean(),inplace=True)\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manage .mat files in Python?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data has been created using MATLAB as data.mat file.\n",
        "* However the source contributor has uploaded the data as CSV files as well. \n",
        "* They indicate the although file structure is slightly different between the .csv the .mat filed, the variable names have been kept however."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the scipy.io.loadmat module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from os.path import dirname, join as pjoin\n",
        "# import scipy.io as sio\n",
        "\n",
        "# data_dir = pjoin(dirname(sio.__file__), 'matlab', 'tests', 'data')\n",
        "# mat_fname = pjoin(data_dir, '/workspace/dataset-testing/inputs/datasets/raw/Data.mat')\n",
        "# mat_contents = sio.loadmat(mat_fname)\n",
        "# sorted(mat_contents.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mat_contents['None']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OR?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy.io import loadmat\n",
        "# annots_data = loadmat(f'inputs/datasets/raw/Data.mat')\n",
        "# annots_fine = loadmat(f'inputs/datasets/raw/Particle size distribution_ISO_12103_1_A2_Fine.mat')\n",
        "# annots_medium = loadmat(f'inputs/datasets/raw/Particle size distribution_ISO_12103_1_A3_Medium.mat')\n",
        "# annots_coarse = loadmat(f'inputs/datasets/raw/Particle size distribution_ISO_12103_1_A4_Coarse.mat')\n",
        "# print(annots_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test.join(\n",
        "    \n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # insert new column at index 8\n",
        "# df_test.insert(\n",
        "#     loc=7,\n",
        "#     column='Dust_Density',\n",
        "#     value=[i for i in range(1000, 2000)]\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Section N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Combine Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combined_list = [df_test, df_train]\n",
        "# df = pd.concat(combined_list)\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with 'Conclusions and Next Steps' and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# try:\n",
        "#   os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "# except Exception as e:\n",
        "#   print(e)\n",
        "\n",
        "# df.to_csv(f'outputs/datasets/collection/FilterMaintenancePredictorDataset.csv',index=False)\n",
        "# df_test.to_csv(f'outputs/datasets/collection/Test_FilterMaintenancePredictorDataset.csv',index=False)\n",
        "# df_train.to_csv(f'outputs/datasets/collection/Train_FilterMaintenancePredictorDataset.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
